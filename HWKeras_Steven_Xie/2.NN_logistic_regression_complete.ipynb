{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing code (#####) to use a NN to define a logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranform the trainy and testy data into 1 and 0 labels\n",
    "##### as many as needed\n",
    "df = pd.DataFrame(trainy, columns=['y'])\n",
    "df['lab']=np.where(df.y.shift(-1)>df.y,1,0) #like price prediction\n",
    "trainy=df.lab.fillna(0).values\n",
    "df = pd.DataFrame(testy, columns=['y'])\n",
    "df['lab']=np.where(df.y.shift(-1)>df.y,1,0) #like price prediction\n",
    "testy=df.lab.fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 384us/step - loss: 1.0238 - acc: 0.5160 - val_loss: 0.8153 - val_acc: 0.5940\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 52us/step - loss: 0.7361 - acc: 0.6020 - val_loss: 0.6390 - val_acc: 0.7140\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.6128 - acc: 0.7340 - val_loss: 0.6147 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.5973 - acc: 0.7700 - val_loss: 0.6132 - val_acc: 0.7540\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 82us/step - loss: 0.5976 - acc: 0.7600 - val_loss: 0.6149 - val_acc: 0.7480\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.5974 - acc: 0.7740 - val_loss: 0.6123 - val_acc: 0.7520\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 64us/step - loss: 0.5973 - acc: 0.7620 - val_loss: 0.6112 - val_acc: 0.7500\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.5973 - acc: 0.7640 - val_loss: 0.6099 - val_acc: 0.7560\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.5974 - acc: 0.7620 - val_loss: 0.6107 - val_acc: 0.7560\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5970 - acc: 0.7640 - val_loss: 0.6110 - val_acc: 0.7520\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.5973 - acc: 0.7740 - val_loss: 0.6100 - val_acc: 0.7460\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 101us/step - loss: 0.5972 - acc: 0.7700 - val_loss: 0.6127 - val_acc: 0.7520\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.5978 - acc: 0.7660 - val_loss: 0.6116 - val_acc: 0.7600\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 78us/step - loss: 0.5971 - acc: 0.7660 - val_loss: 0.6128 - val_acc: 0.7520\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.5976 - acc: 0.7640 - val_loss: 0.6125 - val_acc: 0.7460\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.5978 - acc: 0.7600 - val_loss: 0.6102 - val_acc: 0.7540\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5969 - acc: 0.7620 - val_loss: 0.6116 - val_acc: 0.7540\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5970 - acc: 0.7700 - val_loss: 0.6098 - val_acc: 0.7640\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 86us/step - loss: 0.5967 - acc: 0.7740 - val_loss: 0.6111 - val_acc: 0.7560\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.5974 - acc: 0.7680 - val_loss: 0.6116 - val_acc: 0.7460\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 90us/step - loss: 0.5970 - acc: 0.7700 - val_loss: 0.6116 - val_acc: 0.7420\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 66us/step - loss: 0.5966 - acc: 0.7660 - val_loss: 0.6113 - val_acc: 0.7480\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 116us/step - loss: 0.5976 - acc: 0.7660 - val_loss: 0.6125 - val_acc: 0.7600\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.5972 - acc: 0.7700 - val_loss: 0.6103 - val_acc: 0.7520\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.5974 - acc: 0.7740 - val_loss: 0.6124 - val_acc: 0.7560\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.5969 - acc: 0.7780 - val_loss: 0.6120 - val_acc: 0.7480\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.5976 - acc: 0.7760 - val_loss: 0.6109 - val_acc: 0.7520\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 67us/step - loss: 0.5974 - acc: 0.7720 - val_loss: 0.6121 - val_acc: 0.7500\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.5970 - acc: 0.7620 - val_loss: 0.6119 - val_acc: 0.7560\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.5978 - acc: 0.7600 - val_loss: 0.6117 - val_acc: 0.7540\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.5973 - acc: 0.7640 - val_loss: 0.6128 - val_acc: 0.7520\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.5979 - acc: 0.7600 - val_loss: 0.6105 - val_acc: 0.7540\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5969 - acc: 0.7680 - val_loss: 0.6101 - val_acc: 0.7540\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.5970 - acc: 0.7660 - val_loss: 0.6110 - val_acc: 0.7560\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5973 - acc: 0.7640 - val_loss: 0.6123 - val_acc: 0.7600\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.5971 - acc: 0.7640 - val_loss: 0.6113 - val_acc: 0.7560\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 103us/step - loss: 0.5969 - acc: 0.7640 - val_loss: 0.6123 - val_acc: 0.7460\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5968 - acc: 0.7660 - val_loss: 0.6105 - val_acc: 0.7580\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.5970 - acc: 0.7600 - val_loss: 0.6113 - val_acc: 0.7560\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.5974 - acc: 0.7680 - val_loss: 0.6114 - val_acc: 0.7540\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.5965 - acc: 0.7680 - val_loss: 0.6114 - val_acc: 0.7560\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.5970 - acc: 0.7660 - val_loss: 0.6115 - val_acc: 0.7540\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.5972 - acc: 0.7600 - val_loss: 0.6104 - val_acc: 0.7500\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 89us/step - loss: 0.5975 - acc: 0.7660 - val_loss: 0.6107 - val_acc: 0.7480\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.5981 - acc: 0.7620 - val_loss: 0.6127 - val_acc: 0.7560\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 86us/step - loss: 0.5966 - acc: 0.7620 - val_loss: 0.6132 - val_acc: 0.7480\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 86us/step - loss: 0.5967 - acc: 0.7820 - val_loss: 0.6103 - val_acc: 0.7560\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.5968 - acc: 0.7700 - val_loss: 0.6106 - val_acc: 0.7520\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 86us/step - loss: 0.5978 - acc: 0.7660 - val_loss: 0.6092 - val_acc: 0.7500\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5967 - acc: 0.7560 - val_loss: 0.6121 - val_acc: 0.7520\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.5970 - acc: 0.7780 - val_loss: 0.6108 - val_acc: 0.7560\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 90us/step - loss: 0.5974 - acc: 0.7660 - val_loss: 0.6113 - val_acc: 0.7500\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 90us/step - loss: 0.5978 - acc: 0.7580 - val_loss: 0.6136 - val_acc: 0.7520\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5977 - acc: 0.7700 - val_loss: 0.6118 - val_acc: 0.7460\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5969 - acc: 0.7700 - val_loss: 0.6112 - val_acc: 0.7540\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 78us/step - loss: 0.5969 - acc: 0.7700 - val_loss: 0.6118 - val_acc: 0.7500\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 56us/step - loss: 0.5975 - acc: 0.7640 - val_loss: 0.6108 - val_acc: 0.7520\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.5966 - acc: 0.7700 - val_loss: 0.6111 - val_acc: 0.7540\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 55us/step - loss: 0.5970 - acc: 0.7760 - val_loss: 0.6121 - val_acc: 0.7560\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.5976 - acc: 0.7760 - val_loss: 0.6118 - val_acc: 0.7520\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 99us/step - loss: 0.5969 - acc: 0.7720 - val_loss: 0.6111 - val_acc: 0.7580\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 82us/step - loss: 0.5977 - acc: 0.7680 - val_loss: 0.6124 - val_acc: 0.7480\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.5977 - acc: 0.7660 - val_loss: 0.6112 - val_acc: 0.7560\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 78us/step - loss: 0.5973 - acc: 0.7760 - val_loss: 0.6127 - val_acc: 0.7540\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 78us/step - loss: 0.5973 - acc: 0.7660 - val_loss: 0.6113 - val_acc: 0.7580\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.5968 - acc: 0.7620 - val_loss: 0.6104 - val_acc: 0.7520\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 63us/step - loss: 0.5970 - acc: 0.7680 - val_loss: 0.6099 - val_acc: 0.7520\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.5976 - acc: 0.7620 - val_loss: 0.6130 - val_acc: 0.7580\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.5973 - acc: 0.7680 - val_loss: 0.6114 - val_acc: 0.7540\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.5973 - acc: 0.7560 - val_loss: 0.6101 - val_acc: 0.7580\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.5969 - acc: 0.7760 - val_loss: 0.6111 - val_acc: 0.7480\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 66us/step - loss: 0.5974 - acc: 0.7780 - val_loss: 0.6102 - val_acc: 0.7560\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.5971 - acc: 0.7660 - val_loss: 0.6122 - val_acc: 0.7580\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5973 - acc: 0.7700 - val_loss: 0.6129 - val_acc: 0.7520\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.5980 - acc: 0.7480 - val_loss: 0.6111 - val_acc: 0.7600\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 86us/step - loss: 0.5972 - acc: 0.7600 - val_loss: 0.6113 - val_acc: 0.7540\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 81us/step - loss: 0.5979 - acc: 0.7620 - val_loss: 0.6091 - val_acc: 0.7540\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.5970 - acc: 0.7680 - val_loss: 0.6109 - val_acc: 0.7500\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.5971 - acc: 0.7740 - val_loss: 0.6114 - val_acc: 0.7560\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.5966 - acc: 0.7700 - val_loss: 0.6107 - val_acc: 0.7480\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 67us/step - loss: 0.5973 - acc: 0.7720 - val_loss: 0.6111 - val_acc: 0.7560\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.5969 - acc: 0.7660 - val_loss: 0.6117 - val_acc: 0.7520\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 78us/step - loss: 0.5971 - acc: 0.7660 - val_loss: 0.6100 - val_acc: 0.7540\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 75us/step - loss: 0.5976 - acc: 0.7680 - val_loss: 0.6104 - val_acc: 0.7520\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.5978 - acc: 0.7560 - val_loss: 0.6133 - val_acc: 0.7500\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 82us/step - loss: 0.5974 - acc: 0.7620 - val_loss: 0.6111 - val_acc: 0.7560\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.5968 - acc: 0.7680 - val_loss: 0.6100 - val_acc: 0.7600\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.5978 - acc: 0.7660 - val_loss: 0.6124 - val_acc: 0.7560\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 86us/step - loss: 0.5975 - acc: 0.7700 - val_loss: 0.6129 - val_acc: 0.7480\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.5973 - acc: 0.7720 - val_loss: 0.6116 - val_acc: 0.7560\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 66us/step - loss: 0.5966 - acc: 0.7700 - val_loss: 0.6130 - val_acc: 0.7460\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.5969 - acc: 0.7640 - val_loss: 0.6113 - val_acc: 0.7440\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.5974 - acc: 0.7700 - val_loss: 0.6128 - val_acc: 0.7420\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 81us/step - loss: 0.5969 - acc: 0.7680 - val_loss: 0.6110 - val_acc: 0.7420\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.5974 - acc: 0.7720 - val_loss: 0.6104 - val_acc: 0.7600\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5006 - acc: 0.875 - 0s 84us/step - loss: 0.5971 - acc: 0.7640 - val_loss: 0.6116 - val_acc: 0.7580\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 82us/step - loss: 0.5970 - acc: 0.7740 - val_loss: 0.6111 - val_acc: 0.7540\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 71us/step - loss: 0.5963 - acc: 0.7720 - val_loss: 0.6112 - val_acc: 0.7540\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.5974 - acc: 0.7720 - val_loss: 0.6124 - val_acc: 0.7560\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.5976 - acc: 0.7600 - val_loss: 0.6130 - val_acc: 0.7460\n",
      "500/500 [==============================] - 0s 36us/step\n",
      "500/500 [==============================] - 0s 24us/step\n",
      "Train loss: 0.595, Test loss: 0.613\n",
      "Train metric: 0.766, Test metric: 0.746\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic regression with scaled inputs outputs on the regression problem\n",
    "# define model\n",
    "model = Sequential()#####\n",
    "model.add(Dense(1, activation='sigmoid',kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.L1L2(l1=0.0, l2=0.1),input_dim=20))#####\n",
    "##### as many as needed\n",
    "#compile the model\n",
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9),loss='binary_crossentropy',metrics=['accuracy'])#####\n",
    "history = model.fit(trainX, trainy, epochs=100,validation_data=(testX, testy))\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_e[0], test_e[0])) \n",
    "print('Train metric: %.3f, Test metric: %.3f' % (train_e[1], test_e[1])) \n",
    "#plot loss during training\n",
    "plt.title('Loss / Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For documentation see:\n",
    "https://archive.ph/71DvsÂ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
