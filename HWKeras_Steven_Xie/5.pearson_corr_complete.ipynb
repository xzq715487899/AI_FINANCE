{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing code (#####).  Here you learn to use the pearson_loss function, the penalized_pearson_loss function and the pearson_metric function. See important comment at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import keras.backend as K\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we program the pearson_loss function using tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_loss(y_true, y_pred):\n",
    "    \"\"\"Pearson correlation coefficient\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "    \n",
    "    return  tf.constant(1.0, dtype=x.dtype) - K.square(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we program another version, a penalized_pearson_loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The penalized_pearson_loss maximizes the pearson correlation coefficient between the predicted values and the labels, while trying to have the same mean and variance.  It is the same as pearson_loss except for the addition of a penalty term (0.01*sqdif) so it deals with  noise better:https://archive.md/k5aTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_pearson_loss(x,y, axis=-2):\n",
    "    \"\"\"Penalized Pearson correlation coefficient\"\"\"\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    y = K.cast(y, x.dtype)\n",
    "    n = tf.cast(tf.shape(x)[axis], x.dtype)\n",
    "    xsum = tf.reduce_sum(x, axis=axis)\n",
    "    ysum = tf.reduce_sum(y, axis=axis)\n",
    "    xmean = xsum / n\n",
    "    ymean = ysum / n\n",
    "    xsqsum = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n",
    "    ysqsum = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n",
    "    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n",
    "    corr = cov / (tf.sqrt(xsqsum * ysqsum)+ K.epsilon())\n",
    "    sqdif = tf.reduce_sum(tf.math.squared_difference(x, y), axis=axis) / n / tf.sqrt(ysqsum / n)\n",
    "    return tf.convert_to_tensor( K.mean(tf.constant(1.0, dtype=x.dtype) - corr + (0.01 * sqdif)) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we program the pearson_metric function using py_func."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "py_func is a tf wrapper for a python function. py_func returns a tensor.\n",
    "Below we use py_func to wrap around the python function pearsonr.\n",
    "This use of py_func does NOT work in my setup which is why\n",
    "I commented out the pearson_metric that uses py_func and intead\n",
    "I use the pearson_metric underneath that uses tensors.\n",
    "py_func doesn't always work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def pearson_metric(y_true, y_pred):\n",
    "    \"\"\"Pearson correlation coefficient\"\"\"\n",
    "    \n",
    "    r = tf.py_function(pearsonr, inp=[y_true, y_pred], Tout=tf.float32)\n",
    "    \n",
    "    return  tf.constant(1.0, dtype=y_true.dtype)  - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_metric(y_true, y_pred):\n",
    "    \"\"\"Pearson correlation coefficient programmed using tensors\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "    \n",
    "    return tf.constant(1.0, dtype=x.dtype) - K.square(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 1.0686 - pearson_metric: 0.9433 - val_loss: 0.8568 - val_pearson_metric: 0.9360\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 119us/step - loss: 0.6226 - pearson_metric: 0.7981 - val_loss: 0.3934 - val_pearson_metric: 0.5976\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 125us/step - loss: 0.3358 - pearson_metric: 0.5233 - val_loss: 0.1913 - val_pearson_metric: 0.3246\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 120us/step - loss: 0.1755 - pearson_metric: 0.2987 - val_loss: 0.1181 - val_pearson_metric: 0.2059\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 124us/step - loss: 0.1040 - pearson_metric: 0.1817 - val_loss: 0.0870 - val_pearson_metric: 0.1529\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0760 - pearson_metric: 0.1337 - val_loss: 0.0725 - val_pearson_metric: 0.1276\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0601 - pearson_metric: 0.1050 - val_loss: 0.0646 - val_pearson_metric: 0.1136\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0494 - pearson_metric: 0.0855 - val_loss: 0.0592 - val_pearson_metric: 0.1035\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0479 - pearson_metric: 0.0828 - val_loss: 0.0542 - val_pearson_metric: 0.0944\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0427 - pearson_metric: 0.0734 - val_loss: 0.0502 - val_pearson_metric: 0.0871\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0375 - pearson_metric: 0.0638 - val_loss: 0.0474 - val_pearson_metric: 0.0822\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 120us/step - loss: 0.0345 - pearson_metric: 0.0583 - val_loss: 0.0451 - val_pearson_metric: 0.0780\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 118us/step - loss: 0.0325 - pearson_metric: 0.0547 - val_loss: 0.0425 - val_pearson_metric: 0.0733\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 124us/step - loss: 0.0293 - pearson_metric: 0.0488 - val_loss: 0.0405 - val_pearson_metric: 0.0697\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 88us/step - loss: 0.0285 - pearson_metric: 0.0473 - val_loss: 0.0381 - val_pearson_metric: 0.0652\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 114us/step - loss: 0.0255 - pearson_metric: 0.0418 - val_loss: 0.0361 - val_pearson_metric: 0.0616\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0238 - pearson_metric: 0.0388 - val_loss: 0.0343 - val_pearson_metric: 0.0584\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0239 - pearson_metric: 0.0391 - val_loss: 0.0327 - val_pearson_metric: 0.0556\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 119us/step - loss: 0.0218 - pearson_metric: 0.0354 - val_loss: 0.0312 - val_pearson_metric: 0.0530\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 118us/step - loss: 0.0218 - pearson_metric: 0.0355 - val_loss: 0.0297 - val_pearson_metric: 0.0503\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 114us/step - loss: 0.0190 - pearson_metric: 0.0302 - val_loss: 0.0286 - val_pearson_metric: 0.0485\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 116us/step - loss: 0.0189 - pearson_metric: 0.0303 - val_loss: 0.0275 - val_pearson_metric: 0.0465\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0185 - pearson_metric: 0.0296 - val_loss: 0.0262 - val_pearson_metric: 0.0441\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0179 - pearson_metric: 0.0287 - val_loss: 0.0252 - val_pearson_metric: 0.0424\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0167 - pearson_metric: 0.0266 - val_loss: 0.0243 - val_pearson_metric: 0.0409\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 118us/step - loss: 0.0159 - pearson_metric: 0.0252 - val_loss: 0.0233 - val_pearson_metric: 0.0391\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 116us/step - loss: 0.0153 - pearson_metric: 0.0242 - val_loss: 0.0223 - val_pearson_metric: 0.0375\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 122us/step - loss: 0.0140 - pearson_metric: 0.0220 - val_loss: 0.0218 - val_pearson_metric: 0.0366\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0135 - pearson_metric: 0.0211 - val_loss: 0.0209 - val_pearson_metric: 0.0351\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 125us/step - loss: 0.0137 - pearson_metric: 0.0217 - val_loss: 0.0202 - val_pearson_metric: 0.0340\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 163us/step - loss: 0.0129 - pearson_metric: 0.0205 - val_loss: 0.0196 - val_pearson_metric: 0.0331\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 132us/step - loss: 0.0125 - pearson_metric: 0.0199 - val_loss: 0.0190 - val_pearson_metric: 0.0322\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0122 - pearson_metric: 0.0195 - val_loss: 0.0183 - val_pearson_metric: 0.0310\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 114us/step - loss: 0.0119 - pearson_metric: 0.0190 - val_loss: 0.0180 - val_pearson_metric: 0.0306\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 132us/step - loss: 0.0117 - pearson_metric: 0.0188 - val_loss: 0.0173 - val_pearson_metric: 0.0293\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 126us/step - loss: 0.0109 - pearson_metric: 0.0174 - val_loss: 0.0167 - val_pearson_metric: 0.0285\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 124us/step - loss: 0.0105 - pearson_metric: 0.0169 - val_loss: 0.0163 - val_pearson_metric: 0.0279\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.0106 - pearson_metric: 0.0171 - val_loss: 0.0158 - val_pearson_metric: 0.0270\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 95us/step - loss: 0.0099 - pearson_metric: 0.0160 - val_loss: 0.0155 - val_pearson_metric: 0.0267\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 129us/step - loss: 0.0096 - pearson_metric: 0.0157 - val_loss: 0.0151 - val_pearson_metric: 0.0260\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0094 - pearson_metric: 0.0154 - val_loss: 0.0146 - val_pearson_metric: 0.0253\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0088 - pearson_metric: 0.0143 - val_loss: 0.0143 - val_pearson_metric: 0.0248\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0090 - pearson_metric: 0.0149 - val_loss: 0.0138 - val_pearson_metric: 0.0241\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 130us/step - loss: 0.0086 - pearson_metric: 0.0143 - val_loss: 0.0134 - val_pearson_metric: 0.0234\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0083 - pearson_metric: 0.0138 - val_loss: 0.0130 - val_pearson_metric: 0.0228\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 111us/step - loss: 0.0081 - pearson_metric: 0.0135 - val_loss: 0.0127 - val_pearson_metric: 0.0222\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0078 - pearson_metric: 0.0129 - val_loss: 0.0124 - val_pearson_metric: 0.0219\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 111us/step - loss: 0.0074 - pearson_metric: 0.0124 - val_loss: 0.0121 - val_pearson_metric: 0.0215\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 136us/step - loss: 0.0072 - pearson_metric: 0.0121 - val_loss: 0.0118 - val_pearson_metric: 0.0210\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 136us/step - loss: 0.0075 - pearson_metric: 0.0129 - val_loss: 0.0116 - val_pearson_metric: 0.0207\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 144us/step - loss: 0.0072 - pearson_metric: 0.0123 - val_loss: 0.0114 - val_pearson_metric: 0.0204\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 107us/step - loss: 0.0068 - pearson_metric: 0.0115 - val_loss: 0.0111 - val_pearson_metric: 0.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0068 - pearson_metric: 0.0117 - val_loss: 0.0108 - val_pearson_metric: 0.0194\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 111us/step - loss: 0.0062 - pearson_metric: 0.0107 - val_loss: 0.0105 - val_pearson_metric: 0.0190\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0060 - pearson_metric: 0.0104 - val_loss: 0.0102 - val_pearson_metric: 0.0186\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0060 - pearson_metric: 0.0104 - val_loss: 0.0100 - val_pearson_metric: 0.0181\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0061 - pearson_metric: 0.0108 - val_loss: 0.0097 - val_pearson_metric: 0.0177\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0058 - pearson_metric: 0.0103 - val_loss: 0.0095 - val_pearson_metric: 0.0174\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 115us/step - loss: 0.0054 - pearson_metric: 0.0094 - val_loss: 0.0094 - val_pearson_metric: 0.0172\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 120us/step - loss: 0.0052 - pearson_metric: 0.0093 - val_loss: 0.0092 - val_pearson_metric: 0.0169\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 116us/step - loss: 0.0055 - pearson_metric: 0.0098 - val_loss: 0.0090 - val_pearson_metric: 0.0166\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 118us/step - loss: 0.0052 - pearson_metric: 0.0093 - val_loss: 0.0088 - val_pearson_metric: 0.0163\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 64us/step - loss: 0.0052 - pearson_metric: 0.0093 - val_loss: 0.0086 - val_pearson_metric: 0.0160\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 115us/step - loss: 0.0049 - pearson_metric: 0.0089 - val_loss: 0.0084 - val_pearson_metric: 0.0157\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 66us/step - loss: 0.0049 - pearson_metric: 0.0089 - val_loss: 0.0083 - val_pearson_metric: 0.0155\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0048 - pearson_metric: 0.0088 - val_loss: 0.0082 - val_pearson_metric: 0.0154\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 114us/step - loss: 0.0045 - pearson_metric: 0.0082 - val_loss: 0.0080 - val_pearson_metric: 0.0151\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 107us/step - loss: 0.0045 - pearson_metric: 0.0083 - val_loss: 0.0079 - val_pearson_metric: 0.0148\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0046 - pearson_metric: 0.0086 - val_loss: 0.0077 - val_pearson_metric: 0.0145\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0046 - pearson_metric: 0.0086 - val_loss: 0.0075 - val_pearson_metric: 0.0142\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 120us/step - loss: 0.0041 - pearson_metric: 0.0075 - val_loss: 0.0074 - val_pearson_metric: 0.0141\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 120us/step - loss: 0.0041 - pearson_metric: 0.0077 - val_loss: 0.0072 - val_pearson_metric: 0.0136\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0040 - pearson_metric: 0.0074 - val_loss: 0.0071 - val_pearson_metric: 0.0135\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0041 - pearson_metric: 0.0077 - val_loss: 0.0070 - val_pearson_metric: 0.0134\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0040 - pearson_metric: 0.0076 - val_loss: 0.0068 - val_pearson_metric: 0.0131\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0039 - pearson_metric: 0.0073 - val_loss: 0.0069 - val_pearson_metric: 0.0131\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 111us/step - loss: 0.0037 - pearson_metric: 0.0069 - val_loss: 0.0066 - val_pearson_metric: 0.0127\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0038 - pearson_metric: 0.0071 - val_loss: 0.0066 - val_pearson_metric: 0.0126\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0038 - pearson_metric: 0.0072 - val_loss: 0.0064 - val_pearson_metric: 0.0124\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0035 - pearson_metric: 0.0067 - val_loss: 0.0064 - val_pearson_metric: 0.0124\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0034 - pearson_metric: 0.0064 - val_loss: 0.0062 - val_pearson_metric: 0.0119\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0034 - pearson_metric: 0.0064 - val_loss: 0.0061 - val_pearson_metric: 0.0117\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0034 - pearson_metric: 0.0064 - val_loss: 0.0061 - val_pearson_metric: 0.0118\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0034 - pearson_metric: 0.0065 - val_loss: 0.0059 - val_pearson_metric: 0.0113\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0034 - pearson_metric: 0.0065 - val_loss: 0.0058 - val_pearson_metric: 0.0112\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0031 - pearson_metric: 0.0059 - val_loss: 0.0058 - val_pearson_metric: 0.0112\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0030 - pearson_metric: 0.0058 - val_loss: 0.0057 - val_pearson_metric: 0.0110\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0032 - pearson_metric: 0.0062 - val_loss: 0.0055 - val_pearson_metric: 0.0107\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0035 - pearson_metric: 0.0068 - val_loss: 0.0054 - val_pearson_metric: 0.0105\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 118us/step - loss: 0.0030 - pearson_metric: 0.0058 - val_loss: 0.0055 - val_pearson_metric: 0.0106\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 122us/step - loss: 0.0027 - pearson_metric: 0.0051 - val_loss: 0.0054 - val_pearson_metric: 0.0104\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 116us/step - loss: 0.0030 - pearson_metric: 0.0057 - val_loss: 0.0053 - val_pearson_metric: 0.0103\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.0029 - pearson_metric: 0.0056 - val_loss: 0.0052 - val_pearson_metric: 0.0101\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0028 - pearson_metric: 0.0054 - val_loss: 0.0051 - val_pearson_metric: 0.0099\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0028 - pearson_metric: 0.0054 - val_loss: 0.0050 - val_pearson_metric: 0.0097\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0026 - pearson_metric: 0.0050 - val_loss: 0.0050 - val_pearson_metric: 0.0096\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0026 - pearson_metric: 0.0050 - val_loss: 0.0048 - val_pearson_metric: 0.0094\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0026 - pearson_metric: 0.0050 - val_loss: 0.0048 - val_pearson_metric: 0.0093\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 87us/step - loss: 0.0026 - pearson_metric: 0.0051 - val_loss: 0.0047 - val_pearson_metric: 0.0091\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0024 - pearson_metric: 0.0047 - val_loss: 0.0047 - val_pearson_metric: 0.0091\n",
      "500/500 [==============================] - 0s 33us/step\n",
      "500/500 [==============================] - 0s 30us/step\n",
      "Train loss: 0.002, Test loss: 0.005\n",
      "Train metric: 0.005, Test metric: 0.009\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mlp with scaled inputs outputs on the regression problem using custom loss and custom metric\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model using as loss: penalized_pearson_loss; as metric: pearson_metric AND kears.losses.mean_squared_error\n",
    "model.compile(loss=penalized_pearson_loss, optimizer=SGD(lr=0.01, momentum=0.9), metrics=[pearson_metric])#####\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_e[0], test_e[0])) #when using custom loss and custom metric\n",
    "print('Train metric: %.3f, Test metric: %.3f' % (train_e[1], test_e[1])) #when using custom loss and custom metric\n",
    "#print('Train loss: %.3f, Test loss: %.3f' % (train_e, test_e)) \n",
    "#plot loss during training\n",
    "plt.title('Loss / Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the spearman_loss function for tensorflow 1.5 in spearman_corr_incomplete.ipynb cannot be used without a gradient, you have three options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You can program a gradient for the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You can use the spearman_loss function for tensorflow 2.6 in spearman_corr_TSFL2.ipynb (but we have not tested this).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You can use the penalized_pearson_loss function instead of the spearman_loss function (as we have done here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_pearson_metric</th>\n",
       "      <th>loss</th>\n",
       "      <th>pearson_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856810</td>\n",
       "      <td>0.935969</td>\n",
       "      <td>1.068564</td>\n",
       "      <td>0.943276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.597628</td>\n",
       "      <td>0.622568</td>\n",
       "      <td>0.798119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.191330</td>\n",
       "      <td>0.324607</td>\n",
       "      <td>0.335798</td>\n",
       "      <td>0.523260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_pearson_metric      loss  pearson_metric\n",
       "0  0.856810            0.935969  1.068564        0.943276\n",
       "1  0.393351            0.597628  0.622568        0.798119\n",
       "2  0.191330            0.324607  0.335798        0.523260"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penalized_pearson_loss has the advantage that it is easy to interpret, unlike MSE or a negative value of R-squared (which can arise in a non-linear model). But it has a disadvantage: When penalized_pearson_loss is used as loss (as it is used here), it minimizes 1-covariance and distance.  But it does so at different rates: it minimizes 1-covariance quickly and distance more slowly. This is why, when using the penalized_pearson_loss, the mse_metric converges more slowly. But the important thing is that it (MSE, distance) eventually converges after about 70 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-linear models you can use loss: MSE ('mean_squared_error'), and metric: pearson_metric. You can also experiment with loss: penalized_pearson_loss, and metric: kears.losses.mean_squared_error, making sure that convergence is happening. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see more about the comparative performance of the penalized_pearson_loss, see pearson_corr_TSFL2_EXTRADOCUMENTATION.ipynb (running the ipynb requires tensorflow 2, but you can see the graphs which show that the penalized_pearson_loss minimizes well while dealing with noisy data.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
