{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing code (#####) to use a NN to define a ridge regression. Check for questions at the bottom of the file. For documentation use: https://faroit.com/keras-docs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compatibility issues:\n",
    "compatibility issues may arise depending on the version of keras and tensor flow that is installed\n",
    "if you install the same keras and tensorflow as listed below, they should disappear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name                    Version                   Build  Channel\n",
    "#python 3.7.9\n",
    "#keras                     2.2.4                         0\n",
    "#tensorflow                1.15.0          eigen_py37h9f89a44_0\n",
    "#tensorflow-base           1.15.0          eigen_py37h07d2309_0\n",
    "#tensorflow-estimator      1.15.1             pyh2649769_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Error: 'tensorflow.python.framework.ops' has no attribute '_TensorLike'. See:\n",
    "https://stackoverflow.com/questions/53135439/issue-with-add-method-in-tensorflow-attributeerror-module-tensorflow-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 218us/step - loss: 1.2951 - val_loss: 0.5457\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.2969 - val_loss: 0.1649\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.0940 - val_loss: 0.0603\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.0393 - val_loss: 0.0305\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 86us/step - loss: 0.0240 - val_loss: 0.0215\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0193 - val_loss: 0.0186\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 64us/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 57us/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 73us/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 74us/step - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 59us/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.0162 - val_loss: 0.0161\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 62us/step - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0160 - val_loss: 0.0160\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 66us/step - loss: 0.0159 - val_loss: 0.0159\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 59us/step - loss: 0.0158 - val_loss: 0.0158\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 65us/step - loss: 0.0155 - val_loss: 0.0155\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 56us/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 55us/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 67us/step - loss: 0.0152 - val_loss: 0.0152\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 80us/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 58us/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 71us/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 82us/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 71us/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 53us/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0136 - val_loss: 0.0135\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 77us/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 60us/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 67us/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 66us/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 58us/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 82us/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 62us/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 56us/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 82us/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 71us/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 78us/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 60us/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 71us/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 71us/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 76us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 62us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 60us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 68us/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 70us/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 85us/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 69us/step - loss: 0.0113 - val_loss: 0.0113\n",
      "500/500 [==============================] - 0s 34us/step\n",
      "500/500 [==============================] - 0s 24us/step\n",
      "Train loss: 0.011, Test loss: 0.011\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAee0lEQVR4nO3dfZRcdZ3n8fenHtJJ6OYpaSAkaKKDKEJEbRBXdgeGQRN0RI+zLCg6enQj58gO7voArKOO456zuO64yCpmkc04s45wHAFFjYooiOcgIw0ihoeQ8JgmQpookOd++u4f91b17erq7kqoTuVWfV7n9Omqe2/d+/0l6U9+/bu/e68iAjMzy79CqwswM7PmcKCbmbUJB7qZWZtwoJuZtQkHuplZm3Cgm5m1CQe6mVmbcKCbmbUJB7odcCQ9LunPW3j8hyW9os7y2yTtlrQ98/X9VtRoVk+p1QWYHUgkvRwoRMTDU2xyUURc08B+ShExMtOyvd2H2XTcQ7fckNQl6QpJm9OvKyR1pesWSvqBpOck/UHSLyUV0nWXSHpK0jZJ6yWdOc1h3gqs3YfaTpc0kB7raeAfJP2tpO9I+qakF4D3Szpa0k1pjRsl/cfMPiZtv7d1WGdzD93y5FPAqcBJQADfA/4G+DTwMWAA6E23PRUISccBFwEnR8RmSUuB4jTHOBv4X/tY31HA4cBLSTpLlwDnAP8eeB/QBfwYuB84Gngl8FNJj0bEz9J91G5v1jD30C1P3gP8XURsiYhB4HPAe9N1w8Ai4KURMRwRv4zkznOjJMF4vKRyRDweEY/U27mk+cDJwC+mqeHK9LeAytfnM+vGgM9GxJ6I2JUu+1VEfDcixoCFwGnAJRGxOyLuBa7JtGHC9pl9mDXEgW55cjTwROb9E+kygC8CG4GbJT0q6VKAiNgIfBT4W2CLpOskHU19ZwJ3RMTuaWr464g4NPP16cy6wTqf3VRT/x8iYltNGxZPsb3ZXnGgW55sJhnOqHhJuoyI2BYRH4uIlwF/AfyXylh5RHwrIk5LPxvAF6bY/9nAD19EffXuRZ1dthk4XFJPTRuemmEfZg1xoNuBqixpbuarBFwL/I2kXkkLgc8A3wSQ9DZJfyJJwAskQy2jko6T9GfpydPdwK50XT0r2YcToo2KiE3AHcB/T9u0HPgg8M+zdUzrLA50O1CtJQnfytffAv8N6AfuA34H3JMuAzgWuAXYDvwKuCoibiMZP78ceBZ4GjgC+K+1B5N0ArA9Ip6coa6v1MxDv3sv23U+sJSkt34jyZj7T/dyH2Z1yU8sMgNJnwQWRsQnW12L2b7ytEWzxOOAr/q0XHMP3cysTXgM3cysTbRsyGXhwoWxdOnSVh3ezCyX7r777mcjorfeupYF+tKlS+nv72/V4c3McknSE1Ot85CLmVmbcKCbmbUJB7qZWZvwPHQzy5Xh4WEGBgbYvXu6e6jl39y5c1myZAnlcrnhzzjQzSxXBgYG6OnpYenSpSS37mk/EcHWrVsZGBhg2bJlDX/OQy5mliu7d+9mwYIFbRvmAJJYsGDBXv8W4kA3s9xp5zCv2Jc25i7Q1z+9jb+/eT1bt+9pdSlmZgeU3AX6xi3b+d8/38iz24daXYqZdaDnnnuOq666aq8/d/bZZ/Pcc881v6CM3AV6qZj8GjI8OtbiSsysE00V6KOjUz03JbF27VoOPfTQWaoqkbtZLuU00EfGfJdIM9v/Lr30Uh555BFOOukkyuUy3d3dLFq0iHvvvZcHHniAd7zjHWzatIndu3dz8cUXs2rVKmD8difbt29n5cqVnHbaadxxxx0sXryY733ve8ybN+9F15bDQE9+qXAP3cw+9/37eWDzC03d5/FHH8xn/+LVU66//PLLWbduHffeey+33XYbb33rW1m3bl11euGaNWs4/PDD2bVrFyeffDLvete7WLBgwYR9bNiwgWuvvZavf/3rnHvuuVx//fVccMEFL7r23AV6qeBAN7MDxymnnDJhrviVV17JjTfeCMCmTZvYsGHDpEBftmwZJ510EgCvf/3refzxx5tSS+4CvTrkMuohF7NON11Pen856KCDqq9vu+02brnlFn71q18xf/58Tj/99Lpzybu6uqqvi8Uiu3btakotOTwpmpQ8MuYeupntfz09PWzbtq3uuueff57DDjuM+fPn89BDD3HnnXfu19py10MvFSqzXNxDN7P9b8GCBbzpTW/ihBNOYN68eRx55JHVdStWrGD16tUsX76c4447jlNPPXW/1pa7QK+cFPWQi5m1yre+9a26y7u6uvjRj35Ud11lnHzhwoWsW7euuvzjH/940+rK4ZBLZdqih1zMzLJyF+jl6iwX99DNzLJyF+i+UtTMrL4ZA13SGklbJK2bYv17JN2Xft0h6TXNL3Pc+Bi6A93MLKuRHvo3gBXTrH8M+NOIWA58Hri6CXVNqVz0LBczs3pmnOUSEbdLWjrN+jsyb+8EljShril5HrqZWX3NHkP/IFB/zg4gaZWkfkn9g4OD+3QAz0M3s1ba19vnAlxxxRXs3LmzyRWNa1qgSzqDJNAvmWqbiLg6Ivoioq+3t3efjuN56GbWSgdyoDflwiJJy4FrgJURsbUZ+5xKsSAkD7mYWWtkb5971llnccQRR/Dtb3+bPXv28M53vpPPfe5z7Nixg3PPPZeBgQFGR0f59Kc/zTPPPMPmzZs544wzWLhwIbfeemvTa3vRgS7pJcANwHsj4uEXX9LMyoWCh1zMDH50KTz9u+bu86gTYeXlU67O3j735ptv5jvf+Q6//vWviQje/va3c/vttzM4OMjRRx/ND3/4QyC5x8shhxzCl770JW699VYWLlzY3JpTjUxbvBb4FXCcpAFJH5R0oaQL000+AywArpJ0r6T+Wak0o1SUpy2aWcvdfPPN3Hzzzbz2ta/lda97HQ899BAbNmzgxBNP5JZbbuGSSy7hl7/8JYcccsh+qaeRWS7nz7D+Q8CHmlZRA8rFgi8sMrNpe9L7Q0Rw2WWX8eEPf3jSurvvvpu1a9dy2WWX8eY3v5nPfOYzs15P7q4UhWQu+rAfQWdmLZC9fe5b3vIW1qxZw/bt2wF46qmn2LJlC5s3b2b+/PlccMEFfPzjH+eee+6Z9NnZkLu7LULy1CIPuZhZK2Rvn7ty5Ure/e5388Y3vhGA7u5uvvnNb7Jx40Y+8YlPUCgUKJfLfO1rXwNg1apVrFy5kkWLFs3KSVFFtKan29fXF/39+zbcftoXfs4pSw/nS//hpOYWZWYHvAcffJBXvepVrS5jv6jXVkl3R0Rfve1zOuRS8JCLmVmNXAZ6qeBZLmZmtfIZ6EXPQzfrZK0aKt6f9qWNuQz0clG+UtSsQ82dO5etW7e2dahHBFu3bmXu3Ll79blcznLxPHSzzrVkyRIGBgbY1xv85cXcuXNZsmTvbl6by0AvFeQhF7MOVS6XWbZsWavLOCDldMjF89DNzGrlMtBLRTHiaYtmZhPkM9B9t0Uzs0lyGehl323RzGySXAZ6qVjwkIuZWY1cBnq5IE9bNDOrkctALxUd6GZmtXIZ6Mm0RQ+5mJll5TbQ3UM3M5sol4FeKngeuplZrXwGuodczMwmyWWgJ88U9ZCLmVlWLgO9VCgQAaMedjEzq5ox0CWtkbRF0rop1kvSlZI2SrpP0uuaX+ZEpaIAfGLUzCyjkR76N4AV06xfCRybfq0Cvvbiy5pe2YFuZjbJjIEeEbcDf5hmk3OAf4rEncChkhY1q8B6ysWkbJ8YNTMb14wx9MXApsz7gXTZJJJWSeqX1P9injZSSgPdJ0bNzMY1I9BVZ1ndrnNEXB0RfRHR19vbu88HLBeSQ7qHbmY2rhmBPgAck3m/BNjchP1OqeQhFzOzSZoR6DcB70tnu5wKPB8Rv2/CfqdUPSnqIRczs6oZHxIt6VrgdGChpAHgs0AZICJWA2uBs4GNwE7gA7NVbEWp4B66mVmtGQM9Is6fYX0AH2laRQ3wPHQzs8lyeaWo56GbmU2W00BPh1x86b+ZWVUuA70yhu4eupnZuFwGemXIxSdFzczG5TLQq/PQPW3RzKwqn4FeqJwUdQ/dzKwil4Hum3OZmU2Wy0CvzEP3kIuZ2bhcBno5neUyNOJANzOryGeglyo9dA+5mJlV5DLQx+/l4h66mVlFLgN9/NJ/99DNzCpyGeieh25mNlk+A93z0M3MJslloHseupnZZLkM9GJBSB5yMTPLymWgQzIXfcizXMzMqnIb6KWiPORiZpaR20AvFwueh25mlpHjQBfDvlLUzKwqt4FeKriHbmaW1VCgS1ohab2kjZIurbP+EEnfl/RbSfdL+kDzS53IY+hmZhPNGOiSisBXgZXA8cD5ko6v2ewjwAMR8RrgdODvJc1pcq0TlIsFD7mYmWU00kM/BdgYEY9GxBBwHXBOzTYB9EgS0A38ARhpaqU1SgV5yMXMLKORQF8MbMq8H0iXZX0FeBWwGfgdcHFETEpbSask9UvqHxwc3MeSE6ViwZf+m5llNBLoqrOsNknfAtwLHA2cBHxF0sGTPhRxdUT0RURfb2/vXpY6Ubkoht1DNzOraiTQB4BjMu+XkPTEsz4A3BCJjcBjwCubU2J95WLBl/6bmWU0Euh3AcdKWpae6DwPuKlmmyeBMwEkHQkcBzzazEJrlQrykIuZWUZppg0iYkTSRcBPgCKwJiLul3Rhun418HngG5J+RzJEc0lEPDuLdVMuFtg5NKvnXc3McmXGQAeIiLXA2pplqzOvNwNvbm5p0ysV5WeKmpll5PpKUQ+5mJmNy22gl4ueh25mlpXbQC8VCx5yMTPLyG2glwtiaMQ9dDOzivwGuuehm5lNkNtA990Wzcwmym2gl4sFX/pvZpaR20AvFTwP3cwsK7+BXix4yMXMLCO3gZ48U9RDLmZmFbkN9FKhQASMetjFzAzIc6AXk9u0+8SomVkit4FedqCbmU2Q40BPSveJUTOzRG4DvZQGuk+Mmpklchvo5UIy5OIeuplZIreBXvKQi5nZBLkN9OpJUQ+5mJkBOQ70UsE9dDOzrPwGuqctmplNkNtA9zx0M7OJchzo6ZCLL/03MwMaDHRJKyStl7RR0qVTbHO6pHsl3S/pF80tc7LKGLp76GZmidJMG0gqAl8FzgIGgLsk3RQRD2S2ORS4ClgREU9KOmKW6q2qDLn4pKiZWaKRHvopwMaIeDQihoDrgHNqtnk3cENEPAkQEVuaW+Zk1XnonrZoZgY0FuiLgU2Z9wPpsqxXAIdJuk3S3ZLeV29HklZJ6pfUPzg4uG8Vp0qFyklR99DNzKCxQFedZbUpWgJeD7wVeAvwaUmvmPShiKsjoi8i+np7e/e62CzfnMvMbKIZx9BJeuTHZN4vATbX2ebZiNgB7JB0O/Aa4OGmVFmH56GbmU3USA/9LuBYScskzQHOA26q2eZ7wL+VVJI0H3gD8GBzS52o7FkuZmYTzNhDj4gRSRcBPwGKwJqIuF/Shen61RHxoKQfA/cBY8A1EbFuNgsvl9JZLp6HbmYGNDbkQkSsBdbWLFtd8/6LwBebV9r0xu/l4h66mRnk+kpRz3IxM8vKX6AP74I/PkGJEcDz0M3MKvIX6A/9EL68nPJzjwHuoZuZVeQv0Lt6ACiN7AQ8D93MrCK3gV4c3o7kaYtmZhX5C/Q53cn3PdsoFwp+BJ2ZWSp/gZ720BnaTrkoD7mYmaXyG+h7tlEqFjwP3cwsletALxfFsK8UNTMD8hjopS4olJMeesE9dDOzivwFOkBXNwxtp+QxdDOzqpwGeg/s2U65WPCQi5lZKp+BPqcnHXIRwyMecjEzg7wGelcPDKWzXDwP3cwMyG2gd4/PcvEYupkZkNdAn9NdHUN3D93MLJHPQO/qSWa5FNxDNzOryG+g79mW9NA9D93MDMhzoA9tp1wIP1PUzCyVz0BP77h4kPZ4yMXMLJXPQE/v59KtXb4fuplZKt+Bzm6PoZuZpRoKdEkrJK2XtFHSpdNsd7KkUUl/2bwS60iHXLrZ5SEXM7PUjIEuqQh8FVgJHA+cL+n4Kbb7AvCTZhc5SdpDn88uz0M3M0s10kM/BdgYEY9GxBBwHXBOne3+E3A9sKWJ9dXXlZ4UZafvtmhmlmok0BcDmzLvB9JlVZIWA+8EVk+3I0mrJPVL6h8cHNzbWsdVeuix2ydFzcxSjQS66iyr7RZfAVwSEaPT7Sgiro6Ivojo6+3tbbDEOuYkgT4vdngeuplZqtTANgPAMZn3S4DNNdv0AddJAlgInC1pJCK+24wiJ0l76HPHdnnIxcws1Uig3wUcK2kZ8BRwHvDu7AYRsazyWtI3gB/MWphD+hi6EvNiF8NjY0QE6X8mZmYda8ZAj4gRSReRzF4pAmsi4n5JF6brpx03nxUSzOlm7tgOImB0LCgVHehm1tka6aETEWuBtTXL6gZ5RLz/xZfVgK6D6RrbCcDIWFAq7pejmpkdsPJ5pShAVzdzR5NA90wXM7NcB3oPcyo9dJ8YNTPLcaDP6WbO6A4Ahn21qJlZjgO9q5vySBLo7qGbmeU60Hsoj3rIxcysIr+BPqeH8sh2wEMuZmaQ50Dv6qE0shMx5lkuZmbkOtC7EcF89njIxcyMXAd6cj+Xg/AdF83MIM+BPmf8uaK+46KZWZ4DvWv8MXTP7xxucTFmZq2X40BPh1y0m2e27W5xMWZmrZffQE8fFN3DTra8sKfFxZiZtV5+Az3toR/ZNcKWbQ50M7PcB/pRc4cZ9JCLmVn+A713zrB76GZm5DnQS3NBRQ4vD/HMC+6hm5nlN9Al6Orm8NJunt0+xKjnoptZh8tvoAN0HczBhT2MjgV/2DHU6mrMzFoq34E+p5tudgGwxSdGzazD5TvQu3qYT3JPdJ8YNbNOl/NA76ZrNOmhD/riIjPrcA0FuqQVktZL2ijp0jrr3yPpvvTrDkmvaX6pdXT1UB5NHnLhmS5m1ulmDHRJReCrwErgeOB8ScfXbPYY8KcRsRz4PHB1swuta04PhaEdHDKv7CEXM+t4jfTQTwE2RsSjETEEXAeck90gIu6IiD+mb+8EljS3zCl0dcOebRzR0+WTombW8RoJ9MXApsz7gXTZVD4I/KjeCkmrJPVL6h8cHGy8yql09aSBPsc9dDPreI0Euuosq3sVj6QzSAL9knrrI+LqiOiLiL7e3t7Gq5zKnG4gWNIdvuOimXW8UgPbDADHZN4vATbXbiRpOXANsDIitjanvBmk93NZPH+UwW17iAikev//mJm1v0Z66HcBx0paJmkOcB5wU3YDSS8BbgDeGxEPN7/MKaSBvmjuKEOjYzznJxeZWQebsYceESOSLgJ+AhSBNRFxv6QL0/Wrgc8AC4Cr0h7ySET0zV7ZqfQhF0d2JZf9b9m2h8MOmjPrhzUzOxA1MuRCRKwF1tYsW515/SHgQ80trQEHLQTgSP0R6GbLtt0cd1TPfi/DzOxAkO8rRY84HhBH7EhGeXxi1Mw6Wb4DvasbFrycnuceAPDDos2so+U70AGOWk7pmXV0d5XcQzezjtYGgX4iPP8kL+seZtAXF5lZB8t/oC9aDkBf14Av/zezjpb/QD8qubHjCcUnfPm/mXW0/Ad6dy/0LOLY0Ud55oXdRPjZombWmfIf6ABHLWfxng3sHh5j256RVldjZtYS7RHoi5Zz6M7H6WLIM13MrGO1R6AftZxCjHKcNvnEqJl1rPYI9HSmy6sLj3P343+cYWMzs/bUHoF+6Euh6xDOOORpbvzNUz4xamYdqT0CXYKjTuT1czbx6LM7uHfTc62uyMxsv2uPQAdYtJzDt29gXglu/M1Tra7GzGy/a59AP2o5GtnFu18+xPd/u5mhkbFWV2Rmtl+1T6AvORmA98/9BX/cOcxt67e0uCAzs/2rfQJ94Z9A3wdZsv4bnHnQIx52MbOO0z6BDnDW36FDX8L/KP0f7njwSZ73M0bNrIO0V6B3dcM7rmLBngE+qmv52L/8lhd2O9TNrDO0V6ADLD0N3nAhHyj9hBM3XMV7rlzLA5tfaHVVZmazTq26CKevry/6+/tnZ+dDO+D6D8H6texmDtePnc6el57OkctezXGvPIFjjjiMrlJxdo5tZjaLJN0dEX111zUS6JJWAF8GisA1EXF5zXql688GdgLvj4h7ptvnrAZ6xTMPsPuXV1Ja9y+USO7COBpiG/PZyTz2FOYxrDmMqZR8FYoEBZAICoQEKH2fvI6a96iynPHX1WXpL0CT9gOoQADSxP2O75Px42fXVfdf2Tfj66fZl9J2JfudXJdQuvua403aJtm/Jq0nqUnjr1U9BtX6NMW+q8eo1KsG1lfXFaq1J/svZP5YlKlr4mcrx6jsE8ZrlQrp/pK/q2xNE49dWV5ACBVU3Y8mtb2Qljv+dzJpn1Czj2Sb8RoL6Xqqx1Ch8ou2qusq+5ZEKNlPdfvqcQqVT40fU5k/l7rbpPsuqP4xq6/Hj6FMu8bbYftqukAvNfDhIvBV4CxgALhL0k0R8UBms5XAsenXG4Cvpd9b68jjmfuXq+FtXyAGH2bwift59okHGdmxldizAw1tR6NDKIYpjI1QjDGIYRRBIUYhiWnEGEr/4yswBpVYjkijvBLTyft6207YLv2caj835euJ7wtRqWv8u+ocJ7u8IN8OwQ4cY1H511v7Lx6Y8K99fJvs93qfi8x/zPX2XW8/U+1v2m1qOwDVusd/8mrrZ8Ln4PcvO5dTL/gszTZjoAOnABsj4lEASdcB5wDZQD8H+KdIuvt3SjpU0qKI+H3TK94Xcw9Bx5zMEceczBGntbqYFouACCLGiIj0ayz5gRgLgjFiLPlPIfs+qu+TzyhdR3Uflf0EjJF8T//jqa5nDDL7qBynWhNj6cuATE0whqrHT9dP2MdYtd5kf1SPUWlr5Ucuxki2j0hrHa8x/QOqtkUR4z+QNfVX25b+Bz5+rPH9jO+30saxzOcy+4yoJkLEWDUGJny2zvvKn1u27uqxM39GmZ1P2L66jEgXj39uYtvHMp8j83qMzEaVP9ya7WqOA+m+Y8ptxstL9qcJx84eo/4+VG/5hLozHaIJy2L8eNl2ZeJ60p9fbX1T7bumE1Y6+EhmQyOBvhjYlHk/wOTed71tFgMHRqDbuOyv/62uxcyaqpFZLvV+7mt/f29kGyStktQvqX9wcLCR+szMrEGNBPoAcEzm/RJg8z5sQ0RcHRF9EdHX29u7t7Wamdk0Ggn0u4BjJS2TNAc4D7ipZpubgPcpcSrw/AEzfm5m1iFmHEOPiBFJFwE/IZm2uCYi7pd0Ybp+NbCWZMriRpJpix+YvZLNzKyeRk6KEhFrSUI7u2x15nUAH2luaWZmtjfa79J/M7MO5UA3M2sTDnQzszbRsptzSRoEntjHjy8Enm1iOXnRie3uxDZDZ7a7E9sMe9/ul0ZE3XnfLQv0F0NS/1Q3p2lnndjuTmwzdGa7O7HN0Nx2e8jFzKxNONDNzNpEXgP96lYX0CKd2O5ObDN0Zrs7sc3QxHbncgzdzMwmy2sP3czMajjQzczaRO4CXdIKSeslbZR0aavrmQ2SjpF0q6QHJd0v6eJ0+eGSfippQ/r9sFbX2mySipJ+I+kH6ftOaPOhkr4j6aH07/yNHdLu/5z++14n6VpJc9ut3ZLWSNoiaV1m2ZRtlHRZmm3rJb1lb4+Xq0DPPN90JXA8cL6k41tb1awYAT4WEa8CTgU+krbzUuBnEXEs8LP0fbu5GHgw874T2vxl4McR8UrgNSTtb+t2S1oM/DXQFxEnkNzJ9Tzar93fAFbULKvbxvRn/Dzg1elnrkozr2G5CnQyzzeNiCGg8nzTthIRv4+Ie9LX20h+wBeTtPUf083+EXhHSwqcJZKWAG8Frsksbvc2Hwz8O+D/AkTEUEQ8R5u3O1UC5kkqAfNJHorTVu2OiNuBP9QsnqqN5wDXRcSeiHiM5Hbkp+zN8fIW6FM9u7RtSVoKvBb4V+DIyoND0u9HtLC02XAF8EkqTwdOtHubXwYMAv+QDjVdI+kg2rzdEfEU8D+BJ0mePfx8RNxMm7c7NVUbX3S+5S3QG3p2abuQ1A1cD3w0Il5odT2zSdLbgC0RcXera9nPSsDrgK9FxGuBHeR/mGFG6bjxOcAy4GjgIEkXtLaqlnvR+Za3QG/o2aXtQFKZJMz/OSJuSBc/I2lRun4RsKVV9c2CNwFvl/Q4yVDan0n6Ju3dZkj+TQ9ExL+m779DEvDt3u4/Bx6LiMGIGAZuAP4N7d9umLqNLzrf8hbojTzfNPckiWRM9cGI+FJm1U3AX6Wv/wr43v6ubbZExGURsSQilpL8vf48Ii6gjdsMEBFPA5skHZcuOhN4gDZvN8lQy6mS5qf/3s8kOVfU7u2Gqdt4E3CepC5Jy4BjgV/v1Z4jIldfJM8ufRh4BPhUq+uZpTaeRvKr1n3AvenX2cACkrPiG9Lvh7e61llq/+nAD9LXbd9m4CSgP/37/i5wWIe0+3PAQ8A64P8BXe3WbuBaknMEwyQ98A9O10bgU2m2rQdW7u3xfOm/mVmbyNuQi5mZTcGBbmbWJhzoZmZtwoFuZtYmHOhmZm3CgW5m1iYc6GZmbeL/A3EeMz9FhDgDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ridge with scaled inputs outputs on the regression problem\n",
    "# define model\n",
    "model = Sequential()#####\n",
    "#model.add(Dense(1, input_dim=20, activation= None, )) #####\n",
    "model.add(Dense(25,input_dim=num_features, activation= None))\n",
    "model.add(Dense(1,input_dim=num_features,activation='linear',kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "##### as many as needed\n",
    "#compile the model\n",
    "model.compile(loss=\"mean_squared_error\",optimizer =SGD(lr=0.01, momentum=0.9))\n",
    "#####\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_e, test_e)) \n",
    "#plot loss during training\n",
    "plt.title('Loss / Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to you change the ridge regression to a lasso regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Documentation see:\n",
    "https://archive.ph/DcLvJ\n",
    "https://www.youtube.com/watch?v=xyymDGReKdY&ab_channel=JeffHeaton\n",
    "The provided example uses the Keras functional model, whereas \n",
    "the answer I will provide uses the Keras sequential model, \n",
    "so you will get both versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
